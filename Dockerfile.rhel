FROM rhel7:7-released AS build

RUN yum -y update && yum clean all

RUN yum -y install curl \
    && yum clean all \
    && rm -rf /var/cache/yum

RUN mkdir /build
COPY . /build

WORKDIR /build

ENV RH_HADOOP_PATCH_VERSION 00002
ENV HADOOP_VERSION 3.1.1

ENV HADOOP_RELEASE_URL http://download.eng.bos.redhat.com/brewroot/packages/org.apache.hadoop-hadoop-main/${HADOOP_VERSION}.redhat_${RH_HADOOP_PATCH_VERSION}/1/maven/org/apache/hadoop/hadoop-dist/${HADOOP_VERSION}.redhat-${RH_HADOOP_PATCH_VERSION}/hadoop-dist-${HADOOP_VERSION}.redhat-${RH_HADOOP_PATCH_VERSION}-bin.tar.gz
ENV HADOOP_OUT /build/hadoop-dist/target/hadoop-$HADOOP_VERSION

RUN curl -fSLs \
    $HADOOP_RELEASE_URL \
    -o /tmp/hadoop-dist-bin.tar.gz

RUN mkdir -p $(dirname $HADOOP_OUT) && \
    tar -xvf /tmp/hadoop-dist-bin.tar.gz -C /tmp \
    && mv /tmp/hadoop-${HADOOP_VERSION}.redhat-${RH_HADOOP_PATCH_VERSION}/ \
    $HADOOP_OUT

ENV PROMETHEUS_JMX_EXPORTER_VERSION 0.3.1
ENV RH_PROMETHEUS_JMX_EXPORTER_PATCH_VERSION 00006
ENV RH_PROMETHEUS_JMX_EXPORTER_VERSION ${PROMETHEUS_JMX_EXPORTER_VERSION}.redhat-${RH_PROMETHEUS_JMX_EXPORTER_PATCH_VERSION}
ENV RH_PROMETHEUS_JMX_EXPORTER_BREW_DIR ${PROMETHEUS_JMX_EXPORTER_VERSION}.redhat_${RH_PROMETHEUS_JMX_EXPORTER_PATCH_VERSION}
ENV PROMETHEUS_JMX_EXPORTER_OUT /build/jmx_prometheus_javaagent.jar
ARG PROMETHEUS_JMX_EXPORTER_URL=http://download.eng.bos.redhat.com/brewroot/packages/io.prometheus.jmx-parent/${RH_PROMETHEUS_JMX_EXPORTER_BREW_DIR}/1/maven/io/prometheus/jmx/jmx_prometheus_javaagent/${RH_PROMETHEUS_JMX_EXPORTER_VERSION}/jmx_prometheus_javaagent-${RH_PROMETHEUS_JMX_EXPORTER_VERSION}.jar

RUN set -x; curl -fSLs \
    $PROMETHEUS_JMX_EXPORTER_URL \
    -o $PROMETHEUS_JMX_EXPORTER_OUT

ENV GOOGLE_BIGDATA_OSS_VERSION 1.9.17
ENV RH_GOOGLE_BIGDATA_OSS_PATCH_VERSION 00002
ENV RH_GOOGLE_BIGDATA_OSS_BREW_DIR ${GOOGLE_BIGDATA_OSS_VERSION}.redhat_${RH_GOOGLE_BIGDATA_OSS_PATCH_VERSION}
ENV RH_GCS_CONNECTOR_PATCH_VERSION 00001
ENV RH_GCS_CONNECTOR_VERSION ${GOOGLE_BIGDATA_OSS_VERSION}.hadoop3-redhat-${RH_GCS_CONNECTOR_PATCH_VERSION}
ENV GCS_CONNECTOR_OUT /build/gcs-connector-hadoop3-shaded.jar

ARG GCS_CONNECTOR_URL=http://download.eng.bos.redhat.com/brewroot/packages/com.google.cloud.bigdataoss-bigdataoss-parent/${RH_GOOGLE_BIGDATA_OSS_BREW_DIR}/1/maven/com/google/cloud/bigdataoss/gcs-connector/${RH_GCS_CONNECTOR_VERSION}/gcs-connector-${RH_GCS_CONNECTOR_VERSION}-shaded.jar

RUN set -x; curl -fSLs \
    $GCS_CONNECTOR_URL \
    -o $GCS_CONNECTOR_OUT

FROM rhel7:7-released

RUN set -x; yum install --setopt=skip_missing_names_on_install=False -y \
        java-1.8.0-openjdk \
        java-1.8.0-openjdk-devel \
        curl \
        less  \
        procps \
        net-tools \
        bind-utils \
        which \
        jq \
        rsync \
        openssl \
        faq \
        tini \
    && yum clean all \
    && rm -rf /tmp/* /var/tmp/*

ENV JAVA_HOME=/etc/alternatives/jre

ENV HADOOP_VERSION 3.1.1

ENV HADOOP_HOME=/opt/hadoop
ENV HADOOP_LOG_DIR=$HADOOP_HOME/logs
ENV HADOOP_CLASSPATH=$HADOOP_HOME/share/hadoop/tools/lib/*
ENV HADOOP_CONF_DIR=/etc/hadoop
ENV PROMETHEUS_JMX_EXPORTER /opt/jmx_exporter/jmx_exporter.jar
ENV PATH=$HADOOP_HOME/bin:$PATH

COPY --from=build /build/hadoop-dist/target/hadoop-$HADOOP_VERSION $HADOOP_HOME
COPY --from=build /build/jmx_prometheus_javaagent.jar $PROMETHEUS_JMX_EXPORTER
COPY --from=build /build/gcs-connector-hadoop3-shaded.jar $HADOOP_HOME/share/hadoop/tools/lib/gcs-connector-hadoop3-shaded.jar
WORKDIR $HADOOP_HOME

# remove unnecessary doc/src files
RUN rm -rf ${HADOOP_HOME}/share/doc \
    && for dir in common hdfs mapreduce tools yarn; do \
         rm -rf ${HADOOP_HOME}/share/hadoop/${dir}/sources; \
       done \
    && rm -rf ${HADOOP_HOME}/share/hadoop/common/jdiff \
    && rm -rf ${HADOOP_HOME}/share/hadoop/mapreduce/lib-examples \
    && rm -rf ${HADOOP_HOME}/share/hadoop/yarn/test \
    && find ${HADOOP_HOME}/share/hadoop -name *test*.jar | xargs rm -rf

RUN ln -s $HADOOP_HOME/etc/hadoop $HADOOP_CONF_DIR
RUN mkdir -p $HADOOP_LOG_DIR

# https://docs.oracle.com/javase/7/docs/technotes/guides/net/properties.html
# Java caches dns results forever, don't cache dns results forever:
RUN sed -i '/networkaddress.cache.ttl/d' $JAVA_HOME/lib/security/java.security
RUN sed -i '/networkaddress.cache.negative.ttl/d' $JAVA_HOME/lib/security/java.security
RUN echo 'networkaddress.cache.ttl=0' >> $JAVA_HOME/lib/security/java.security
RUN echo 'networkaddress.cache.negative.ttl=0' >> $JAVA_HOME/lib/security/java.security

# imagebuilder expects the directory to be created before VOLUME
RUN mkdir -p /hadoop/dfs/data /hadoop/dfs/name

VOLUME /hadoop/dfs/data /hadoop/dfs/name

USER 1002

LABEL io.k8s.display-name="OpenShift Hadoop" \
      io.k8s.description="This is an image used by operator-metering to to install and run HDFS." \
      io.openshift.tags="openshift" \
      maintainer="AOS Operator Metering <sd-operator-metering@redhat.com>"

